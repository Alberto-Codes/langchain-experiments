{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alberto-Codes/langchain-experiments/blob/main/financial_rag_langsmith.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os"
      ],
      "metadata": {
        "id": "HMx-_kefhEPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your Cohere API key\n",
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "id": "4NSUcGBcXmOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "id": "Joom9Q8dyMgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "id": "2FDEgBeGaNAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1DNAGjvg73A"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q langchain cohere tiktoken unstructured==0.12.5 openai pandas langchain-community chromadb langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download SEC filing"
      ],
      "metadata": {
        "id": "3PcCEBN4kI1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import UnstructuredURLLoader\n",
        "\n",
        "url = \"https://www.sec.gov/Archives/edgar/data/1559720/000155972024000006/abnb-20231231.htm\"\n",
        "loader = UnstructuredURLLoader(urls=[url], headers={'User-Agent': 'virat virat@virat.com'})\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "VmGucGdHhAii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Index SEC filing"
      ],
      "metadata": {
        "id": "cXwTQca78vtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### INDEX\n",
        "\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "from langchain_community.document_loaders import UnstructuredURLLoader\n",
        "\n",
        "# Load\n",
        "url = \"https://www.sec.gov/Archives/edgar/data/1559720/000155972024000006/abnb-20231231.htm\"\n",
        "loader = UnstructuredURLLoader(urls=[url], headers={'User-Agent': 'virat virat@virat.com'})\n",
        "docs = loader.load()\n",
        "\n",
        "# Split\n",
        "text_splitter = TokenTextSplitter(chunk_size=256, chunk_overlap=20)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "# Embed\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
        "\n",
        "# Index\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "DC5g0ED-Yo5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build RAG chain"
      ],
      "metadata": {
        "id": "4iUOhsOrZRE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "You are an expert language model designed to\n",
        "answer questions about financial documents like\n",
        "SEC filings.\n",
        "\n",
        "Given financial documents, your primary role is to extract key information\n",
        "and providing accurate answers to questions\n",
        "related to these filings.\n",
        "\n",
        "In your response, optimize for conciseness, accuracy, and correctness.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Q41kYo3-Z0mB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "import cohere\n",
        "\n",
        "co = cohere.Client(os.environ[\"COHERE_API_KEY\"])\n",
        "\n",
        "\n",
        "def rerank_documents(query: str, documents: list, top_k) -> List[str]:\n",
        "  response = co.rerank(\n",
        "      query=query,\n",
        "      documents=documents,\n",
        "      top_n=top_k,\n",
        "      model=\"rerank-english-v3.0\",\n",
        "      return_documents=True\n",
        "  )\n",
        "  results = response.results\n",
        "  return [{\"text\": docs.document.text} for docs in results]\n",
        "\n",
        "def answer_question(query: str, documents: list, prompt: str) -> str:\n",
        "  message = f\"{prompt}. Please answer the question: ```{query}```.\"\n",
        "  response = co.chat(\n",
        "      model=\"command-r-plus\",\n",
        "      temperature=0,\n",
        "      message=message,\n",
        "      documents=documents,\n",
        "  )\n",
        "  return response.text"
      ],
      "metadata": {
        "id": "_4JNn0OdZbUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### RAG\n",
        "\n",
        "import openai\n",
        "from langsmith import traceable\n",
        "from langsmith.wrappers import wrap_openai\n",
        "\n",
        "k = 3\n",
        "\n",
        "class RagBot:\n",
        "    @traceable\n",
        "    def get_answer(self, question: str):\n",
        "      print(f\"Question: {question}\")\n",
        "      print()\n",
        "\n",
        "      top_k_docs = vectorstore.similarity_search(question, k)\n",
        "\n",
        "      # Extract the text content from documents\n",
        "      documents = [{\"text\": doc.page_content} for doc in top_k_docs]\n",
        "\n",
        "      # Rerank the documents\n",
        "      documents = rerank_documents(question, documents, k)\n",
        "\n",
        "      # Ask the LLM\n",
        "      answer = answer_question(question, documents, prompt)\n",
        "\n",
        "      # Evaluators will expect \"answer\" and \"contexts\"\n",
        "      return {\n",
        "          \"answer\": answer,\n",
        "          \"contexts\": [str(doc) for doc in documents],\n",
        "      }\n",
        "\n",
        "rag_bot = RagBot()"
      ],
      "metadata": {
        "id": "UJXGNjtTZTW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_bot.get_answer(\"What is Airbnb's revenue in 2023?\")\n",
        "response[\"answer\"][:150]"
      ],
      "metadata": {
        "id": "q4TANAtnZ8AG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Q&A Dataset"
      ],
      "metadata": {
        "id": "ben3cKdnw1mU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'"
      ],
      "metadata": {
        "id": "_97LEXpjaJ6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# URL of the JSON file\n",
        "url = 'https://raw.githubusercontent.com/virattt/datasets/main/abnb-2023-10k.json'\n",
        "\n",
        "# Fetch the JSON content from the URL\n",
        "response = requests.get(url)\n",
        "data = response.json()"
      ],
      "metadata": {
        "id": "mAZHxmr4-u0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "for row in data:\n",
        "  question = row['question']\n",
        "  answer = row['answer']\n",
        "  inputs.append(question)\n",
        "  outputs.append(answer)\n",
        "\n",
        "qa_pairs = [{\"question\": q, \"answer\": a} for q, a in zip(inputs, outputs)]"
      ],
      "metadata": {
        "id": "6pZN22qnalYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langsmith import Client\n",
        "\n",
        "# Create dataset\n",
        "client = Client()\n",
        "dataset_name = \"financial-rag-test-1.3\"\n",
        "dataset = client.create_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    description=\"QA pairs about LCEL.\",\n",
        ")\n",
        "client.create_examples(\n",
        "    inputs=[{\"question\": q} for q in inputs],\n",
        "    outputs=[{\"answer\": a} for a in outputs],\n",
        "    dataset_id=dataset.id,\n",
        ")"
      ],
      "metadata": {
        "id": "S3DMMmVJa7Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "ffUOAun6bHZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG chain\n",
        "def predict_rag_answer(example: dict):\n",
        "    \"\"\"Use this for answer evaluation\"\"\"\n",
        "    response = rag_bot.get_answer(example[\"question\"])\n",
        "    return {\"answer\": response[\"answer\"]}\n",
        "\n",
        "def predict_rag_answer_with_context(example: dict):\n",
        "    \"\"\"Use this for evaluation of retrieved documents and hallucinations\"\"\"\n",
        "    response = rag_bot.get_answer(example[\"question\"])\n",
        "    return {\"answer\": response[\"answer\"], \"contexts\": response[\"contexts\"]}"
      ],
      "metadata": {
        "id": "MN_7K8HIbERu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
        "\n",
        "# Evaluator\n",
        "qa_evalulator = [\n",
        "    LangChainStringEvaluator(\n",
        "        \"qa\",\n",
        "        prepare_data=lambda run, example: {\n",
        "            \"prediction\": run.outputs[\"answer\"],\n",
        "            \"reference\": example.outputs[\"answer\"],\n",
        "            \"input\": example.inputs[\"question\"],\n",
        "        },\n",
        "      ),\n",
        "]\n",
        "experiment_results = evaluate(\n",
        "    predict_rag_answer,\n",
        "    data=dataset_name,\n",
        "    evaluators=qa_evalulator,\n",
        "    experiment_prefix=\"financial-rag-qa\",\n",
        "    metadata={\"variant\": \"LCEL context, gpt-3.5-turbo\"},\n",
        ")"
      ],
      "metadata": {
        "id": "zMwMJI1WbE0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OgR0AHsOdJcO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}